kubernetesClusterDomain: cluster.local

# Default values for skaha.
# This is a YAML-formatted file.
# Declare variables to be passed into your templates.

# Tell Kubernetes to spin up multiple instances.  Defaults to 1.
replicaCount: 1

# It's best to keep this set as such, unless you're willing to change these in several places.
skahaWorkload:
  namespace: skaha-workload

# @param securityContext - Optional security context for the container.  This is a security feature to restrict system calls.
# securityContext: {}
#
# Example:
# securityContext:
#   seccompProfile:
#     type: RuntimeDefault
securityContext: {}

# @param podSecurityContext - Optional pod security context for the deployment.
# podSecurityContext: {}
#
# Example:
# podSecurityContext:
#   fsGroup: 1000
#   runAsUser: 1000
#   allowPrivilegeEscalation: false
podSecurityContext: {}

# Skaha web service deployment
deployment:
  hostname: myhost.example.com  # Change this!
  skaha:
    image: images.opencadc.org/platform/skaha:1.2.0
    imagePullPolicy: Always

    # Cron string for the image caching cron job schedule. Defaults to every half hour.
    imageCache:
      refreshSchedule: "*/30 * * * *"

    # Used when allocating first-time users into the system.
    defaultQuotaGB: "10"

    # Space delimited list of allowed Image Registry hosts.  These hosts should match the hosts in the User Session images.
    registryHosts: "images.canfar.net"

    init:
      # The image to use for the init container.  Unless you have a reason to change this, leave it alone.
      # This image is used to create the /home and /projects directories, in case Cavern is not already running.
      image: busybox:1.37.0
      imagePullPolicy: IfNotPresent

    # Optionally set the TTL (Time To Live) for POSIX Mapper cache entries, in seconds.  Defaults to 86400 seconds (1 day) if not set.
    # This is used to cache POSIX user and group information to reduce load on the POSIX Mapper service.
    posixMapperCacheTTLSeconds: "86400"

    # The IVOA GMS Group URI to verify users against for permission to use the Science Platform.
    # See https://www.ivoa.net/documents/GMS/20220222/REC-GMS-1.0.html#tth_sEc3.2
    # usersGroup: "ivo://example.org/gms?prototyping-groups/mini-src/platform-users"

    # The IVOA GMS Group URI to verify images without contacting Harbor.
    # See https://www.ivoa.net/documents/GMS/20220222/REC-GMS-1.0.html#tth_sEc3.2
    # adminsGroup: "ivo://example.org/gms?prototyping-groups/mini-src/platform-users"

    # Group URI for users to preempt headless jobs.
    # See https://www.ivoa.net/documents/GMS/20220222/REC-GMS-1.0.html#tth_sEc3.2
    # headlessGroup: "ivo://example.org/gms?prototyping-groups/mini-src/platform-users"

    # Group URI for users to ensure priority for their headless jobs.
    # See https://www.ivoa.net/documents/GMS/20220222/REC-GMS-1.0.html#tth_sEc3.2
    # headlessPriorityGroup: "ivo://example.org/gms?skaha-priority-headless-users"

    # Class name to set for priority headless jobs.
    # headlessPriorityClass: uber-user-preempt-high

    # Array of GMS Group URIs allowed to set the logging level.  If none set, then nobody can change the log level.
    # See https://www.ivoa.net/documents/GMS/20220222/REC-GMS-1.0.html#tth_sEc3.2 for GMS Group URIs
    # See https://github.com/opencadc/core/tree/main/cadc-log for Logging control
    # loggingGroups:
    #   - "ivo://example.org/gms?prototyping-groups/mini-src/platform-users"

    # The Resource ID (URI) of the Service that contains the Posix Mapping information
    # posixMapperResourceID: "ivo://example.org/posix-mapper"

    # URI or URL of the OIDC (IAM) server.  Used to validate incoming tokens.
    # oidcURI: https://iam.example.org/

    # The Resource ID (URI) of the GMS Service.
    # gmsID: ivo://example.org/gms

    # The absolute URL of the IVOA Registry where services are registered
    # registryURL: https://spsrc27.iaa.csic.es/reg

    # This applies to Skaha itself.  Meaning, this Pod will be scheduled as described
    # by the nodeAffinity clause.
    # Note the different indentation level compared to the sessions.nodeAffinity.
    # See https://kubernetes.io/docs/tasks/configure-pod-container/assign-pods-nodes-using-node-affinity/
    # nodeAffinity: {}

    # Settings for User Sessions.  Sensible defaults supplied, but can be overridden.
    # For units of storage, see https://kubernetes.io/docs/concepts/configuration/manage-resources-containers/#meaning-of-memory.
    sessions:
      expirySeconds: "345600"   # Duration, in seconds, until they expire and are shut down.
      maxCount: "5"  # Max number of sessions per user.
      minEphemeralStorage: "20Gi"   # The initial requested amount of ephemeral (local) storage.  Does NOT apply to Desktop sessions.
      maxEphemeralStorage: "200Gi"  # The maximum amount of ephemeral (local) storage to allow a Session to extend to.  Does NOT apply to Desktop sessions.

      # YAML to pass to a LimitRange object called "{{ .Release.Name }}-session-limit-range" in the workload Namespace to define the resource limits.
      # These limits will be applied to Container objects (User Sessions).
      # This replaces the previously feature gated "experimentalFeatures.sessionLimitRange" configuration.
      # **NOTE**: Pay attention to the deployment.skaha.sessions.flexResourceRequests above as these two features can conflict.
      # **NOTE**: This requires the experimentalFeatures.enabled to be true as well as the sessionLimitRange.enabled to be true.
      # **NOTE**: The min clause is ignored due to hard-coded resources for Desktop and Firefly sessions.  The `defaultRequest` is used instead for these session types.
      # See https://kubernetes.io/docs/concepts/policy/limit-range/
      #
      # Example:
      # limitRange:
      #   enabled: true
      #   rbac:
      #     create: true
      #   spec:
      #     max:
      #       memory: "96Gi"
      #       cpu: "12"
      #       "nvidia.com/gpu": "4" # Can request up to 4 GPUs, though
      #     default:  # actually refers to default limit
      #       memory: "32Gi"
      #       cpu: "8"
      #       "nvidia.com/gpu": "0"
      #     defaultRequest:
      #       memory: "4Gi"
      #       cpu: "1"
      #       "nvidia.com/gpu": "0"
      limitRange:
        enabled: false

      # Resource requests and limits for different session types for resource allocation when a "Flex" resource profile is used.
      # This is used to set resource requests for new User Sesssions based on type.  The LimitRange will be enforced still, and this
      # configuration ONLY applies when the "flex" resource profile is requested, and only for resource requests (not limits).
      # Sensible defaults are provided, but can be overridden as needed.
      #
      # Omit this entire object to use the LimitRange values for all session types.
      #
      # Important:
      # Use memoryInGB and cpuCores to specify resources, valid values are floating point or integer numbers as strings.  The Kubernetes units
      # will be applied by the service and are not supported in this specification.  Any session type not specified here will use the values from the LimitRange.
      #
      # Example:
      # flexResourceRequests:
      #   # Default resource requests applied to all session types if not overridden below.
      #   notebook:
      #     memoryInGB: "2"
      #     cpuCores: "0.1"
      #   # The headless session type resource requests get slightly more resources.
      #   headless:
      #     memoryInGB: "2"
      #     cpuCores: "1"
      flexResourceRequests:
        # The headless session type resource requests get slightly more resources.
        headless:
          memoryInGB: "4"
          cpuCores: "1"

      # Storage setings to be passed into the User Session Kubernetes Job spec.
      userStorage:
        # Required.  ABSOLUTE path mount point to where the top level directory is mounted in the User Sessions.  For most, this can be set to "/cavern", and
        # it is expected that the "/home" and the "/projects" folders will be found under this path (i.e. "/cavern/home" and "/cavern/projects").
        # Example:
        #   topLevelDirectory: "/cavern"
        #
        topLevelDirectory: "/cavern"

        # Required.  RELATIVE path to the User Storage Home folder.  This is the folder where the User's home directories will be created.  Defaults to "home".
        # Example:
        #   homeDirectory: "home"
        #
        homeDirectory: "home"

        # Required.  RELATIVE path to the User Storage Projects folder.  This is the folder where the Users can share data.  This is used for CARTA sessions.  Defaults to "projects".
        # Example:
        #   projectsDirectory: "projects"
        #
        projectsDirectory: "projects"

        # Optional. Name of the Persistent Volume Claim to use for User Storage when mounted into sessions.  Defaults to "skaha-workload-cavern-pvc".
        # Example:
        #   persistentVolumeClaimName: "skaha-workload-cavern-pvc"
        persistentVolumeClaimName: "skaha-workload-cavern-pvc"

        # Required.  The VOSpace Service URI (uses ivo:// scheme) for the Cavern Service.
        # This is the VOSpace location where user home directories will be created, as well as any other user data.  Requires Cavern to be running.
        # Example:
        #   serviceURI: "ivo://example.org/cavern"
        # serviceURI:

        # Required.  The VOSpace Resource ID (Node URI) prefix (uses vos:// scheme) for the Cavern Service.
        # Example:
        #   nodeURIPrefix: "vos://skao.int~cavern"
        # nodeURIPrefix:

        # Required.  These are the credentials and details to connect to the Cavern service to provide Administrative access to User Storage, namely creating new allocations.
        admin:
          auth:
            # Authenticate with an agreed API Key between Skaha and Cavern.  This is used to create new user home directories (allocations).
            # Generate Key:
            #   $ openssl rand -base64 32
            #   $ jMTZdM/qqZ0knXUXbiX8T4T0CyGnhqWdJS2tVLZta2I=
            # Example:
            #   apiKey: "jMTZdM/qqZ0knXUXbiX8T4T0CyGnhqWdJS2tVLZta2I="  # Ensure this value is also used in the Cavern deployment's apiKeys object as "skaha:jMTZdM/qqZ0knXUXbiX8T4T0CyGnhqWdJS2tVLZta2I=".
            # apiKey:

            # Alternatively, you can specify a Kubernetes Secret that contains a PEM Client Certificate representing the User Storage Admin.
            # If both this and the OIDC Client are specified, Helm will throw an error.
            # Default key is "cadcproxy.pem", but you can override it.
            # Example:
            #   certificateSecret:
            #     name: "science-platform-user-storage-admin-certificate"
            #     key: "certificate.pem"  # The key in the Secret that contains the PEM certificate
            # certificateSecret:

      # The image pull policy for User Sessions (applies to ALL types).  This is the default, but can be overridden.  Defaults to Always.
      # @see https://kubernetes.io/docs/concepts/containers/images/#image-pull-policy
      # Example:
      #   imagePullPolicy: IfNotPresent
      imagePullPolicy: Always

      # Optionally configure the initContainer image for Redis.  Useful for those not able to reach docker.io
      # Defaults to redis:8.2.2-bookworm.
      # Example:
      #   initContainerImage: "private-image-repo/project/my-own-redis:1.0"
      # initContainerImage:
      initContainerImage: "redis:8.2.2-bookworm"

      # Optionally set the node label selector to identify Kubernetes Worker Nodes.  This is used to accurately query for available
      # resources from schedulable Nodes by eliminating, for example, Nodes that are only cordoned for Web APIs.
      # Example:
      #   nodeLabelSelector: "node-role.kubernetes.io/node-type=worker"
      #
      # Example (multiple labels ANDed):
      #   nodeLabelSelector: "node-role.kubernetes.io/node-type=worker,environment=production"
      #
      #
      # Example (multiple labels ORed):
      #   nodeLabelSelector: "node-role.kubernetes.io/node-type in (worker,worker-gpu)"
      nodeLabelSelector:

      # Optionally configure the Kueue system to handle large workloads.  Configurable per session type (e.g. desktop, notebook, etc.).
      # Leaving this empty will default to submitting Jobs to the base Kubernetes system.
      # Provide a default configuration for all session types, or omit and only configure specific session types.
      # Provided PriorityClass names are "high", "medium", and "low".
      # @see https://kueue.sigs.k8s.io/docs/
      # @see https://github.com/opencadc/deployments/tree/main/configs/kueue
      # Example 1:
      #   # Configure notebook, desktop, and default session types.
      #   kueue:
      #     notebook:
      #       queueName: "notebook-queue"
      #       priorityClass: "medium"
      #     desktop:
      #       queueName: "desktop-queue"
      #       priorityClass: "low"
      #     default:
      #       queueName: "default-queue"
      #       priorityClass: "medium"
      #
      # Example 2:
      #    # Configure contributed session types.  All else will use the bare Kubernetes system.
      #    kueue:
      #      contributed:
      #        queueName: "contributed-queue"
      #        priorityClass: "high"
      #
      # Example 3:
      #    # Configure Kueue for all user session types.
      #    kueue:
      #      default:
      #        queueName: "all-user-sessions-local-queue"
      #        priorityClass: "medium"
      kueue: {}

      # This is a list of tolerations that will be added to the Pod spec of the User Sessions.
      # @see https://kubernetes.io/docs/concepts/configuration/taint-and-toleration/
      # @see ./README.md#notes-on-tolerations-and-nodeaffinity
      #
      # Example:
      # tolerations:
      # - key: "key1"
      #   operator: "Equal"
      #   value: "value1"
      #   effect: "NoSchedule"
      #
      tolerations: []

      # Optionally setup a separate host for User Sessions for Skaha to redirect to.  The HTTPS scheme is assumed.  Defaults to the Skaha hostname.
      # Example:
      #   hostname: myhost.example.org
      # hostname:

      ingress:
        # Optionally set the TLS configiuration that contains the certificate information for the alternate hostname for User Sessions.  This will go into the Traefik IngressRoute spec.
        # @see https://doc.traefik.io/traefik/v2.3/routing/providers/kubernetes-crd/#kind-ingressroute
        # Example:
        #   tls:
        #     secretName: myhost-tls-secret
        tls: {}

        # Add custom response headers to User Sessions.  This is useful for Science Gateway embedding support.
        # Example:
        #   customResponseHeaders:
        #     content-security-policy: "frame-ancestors 'self' https://gateway.example.org"
        customResponseHeaders: {}

      # Declare extra volume mounts in User Sessions.  The "type: parameter in volume section is constant.
      # extraVolumes:
      # - name: example-pvc-name
      #   volume:
      #     type: PVC           # PVC is for Persistant volume claim
      #     name: pvc-name
      #   volumeMount:
      #     mountPath: "/pvc-volume-mount"
      #     subPath: "pvc"
      # - name: example-hostpath-name
      #   volume:
      #     type: HOST_PATH     # HOST_PATH is for host path
      #     hostPath: "/host-path"
      #     hostPathType: Directory
      #   volumeMount:
      #     mountPath: "/host-path"
      #     readOnly: true
      #     mountPropagation: HostToContainer
      # - name: config-map-volume
      #   volume:
      #     type: CONFIG_MAP    # CONFIG_MAP is for config map
      #     name: example-config-map-name
      #     defaultMode: "0777"
      #   volumeMount:
      #     mountPath: "/cmp"
      # - name: secret-volume
      #   volume:
      #     type: SECRET        # SECRET is for secrets
      #     name: example-secret-name
      #     defaultMode: "0777"
      #   volumeMount:
      #     mountPath: "/scrt"

      # When set to 'true' this flag will enable GPU node scheduling.  Don't forget to declare any related GPU configurations, if appropriate, in the nodeAffinity below!
      # gpuEnabled: false

      # Set the YAML that will go into the "affinity.nodeAffinity" stanza for Pod Spec in User Sessions.  This can be used to enable GPU scheduling, for example,
      # or to control how and where User Session Pods are scheduled.  This can be potentially dangerous unless you know what you are doing.
      # See https://kubernetes.io/docs/tasks/configure-pod-container/assign-pods-nodes-using-node-affinity
      # nodeAffinity: {}

    # Optionally set the DEBUG port.
    # extraEnv:
    # - name: CATALINA_OPTS
    #   value: "-agentlib:jdwp=transport=dt_socket,server=y,suspend=n,address=0.0.0.0:5555"
    # - name: JAVA_OPTS
    #   value: "-agentlib:jdwp=transport=dt_socket,server=y,suspend=n,address=0.0.0.0:5555"

    # Resources provided to the Skaha service.
    # For units of storage, see https://kubernetes.io/docs/concepts/configuration/manage-resources-containers/#meaning-of-memory.
    resources:
      requests:
        memory: "2Gi"
        cpu: "1000m"
      limits:
        memory: "3Gi"
        cpu: "2000m"

    # Uncomment to debug.  Requires options above as well as service port exposure below.
    # extraPorts:
    # - containerPort: 5555
    #   protocol: TCP

    # Optionally mount a custom CA certificate
    # extraVolumeMounts:
    # - mountPath: "/config/cacerts"
    #   name: cacert-volume

    # If the base names have changed, then change them here, otherwise leave them.
    priorityClassName: uber-user-preempt-high
    serviceAccountName: skaha

    # The IdentityManager class handling authentication.  This should generally be left alone
    identityManagerClass: org.opencadc.auth.StandardIdentityManager

    # Create the CA certificate volume to be mounted in extraVolumeMounts
    # extraVolumes:
    # - name: cacert-volume
    #   secret:
    #     defaultMode: 420
    #     secretName: skaha-cacert-secret

    # API version that is currently in use for this deployment.  Leave this alone unless you know what you're doing.
    # This the version that will show up in the path for the request (e.g. '/skaha/v0/session').
    # Example:
    #   apiVersion: 'v0'
    apiVersion: 'v1'

  # Specify extra hostnames that will be added to the Pod's /etc/hosts file.  Note that this is in the
  # deployment object, not the skaha one.
  # extraHosts:
  #   - ip: 127.3.34.5
  #     hostname: myhost.example.org
  # extraHosts: []

# This is a list of tolerations that will be added to the Pod spec of the Skaha API.
# @see https://kubernetes.io/docs/concepts/configuration/taint-and-toleration/
# @see ./README.md#notes-on-tolerations-and-nodeaffinity
#
# Example:
# tolerations:
# - key: "key1"
#   operator: "Equal"
#   value: "value1"
#   effect: "NoSchedule"
#
tolerations: []

# Port to expose from the service.  This will ultimately serve port 8080 (default Tomcat port), but will
# be exposed as per the port below.  Useful for running multiple deployments side-by-side.
# Defaults to 8080.
# Example:
#   service:
#     port: 8081. # To map port 8081 to port 8080.
service:
  port: 8080

# Selectively disable ingress if desired.  This is enabled by default.
ingress:
  enabled: true
  path: /skaha

# Experimental features that can be enabled.  These represent features that are not released and confined behind feature flags.
experimentalFeatures:
  enabled: false

  # @deprecated Use deployment.skaha.sessions.limitRange instead.  Here for backward compatibility.
  sessionLimitRange: {}

secrets:
  # Uncomment to enable local or self-signed CA certificates for your domain to be trusted.
  # skaha-cacert-secret:
  #   ca.crt: <base64 encoded CA crt>

# For caching images from the Image Repository and for the writing the POSIX Users and Groups to be shared with Job files
redis:
  image:
    repository: redis
    tag: 8.2.2-bookworm
  architecture: 'standalone'
  auth:
    enabled: false
  master:
    persistence:
      enabled: false
    containerSecurityContext:
      runAsUser: 1001
      runAsGroup: 1001
      runAsNonRoot: true
      allowPrivilegeEscalation: false
      readOnlyRootFilesystem: true
      seccompProfile:
        type: RuntimeDefault
      capabilities:
        drop: ["ALL"]
